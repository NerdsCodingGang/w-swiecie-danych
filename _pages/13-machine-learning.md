---
title: 13. Jak dziaÅ‚a uczenie maszynowe od Å›rodka?
layout: post
---

W tej lekcji zajrzymy trochÄ™ gÅ‚Ä™biej pod powierzchniÄ™ tego, co robi model ML, kiedy â€uczy siÄ™â€ na danych.  Do tej pory trenowaÅ‚yÅ›my modele tak po prostu â€“ kilka komend i dziaÅ‚a. Teraz zobaczymy, **co naprawdÄ™ dzieje siÄ™ w Å›rodku**.

Nie chcemy traktowaÄ‡ modelu jak czarnej skrzynki, sprÃ³bujemy zrozumieÄ‡, *dlaczego coÅ› dziaÅ‚a*, *dlaczego czasem nie dziaÅ‚a* i *co moÅ¼na poprawiÄ‡?*.

## Uczenie Maszynowe

Machine learning, czyli uczenie maszynowe, to tak naprawdÄ™ **bardzo uporzÄ…dkowany sposÃ³b uczenia komputerÃ³w na podstawie doÅ›wiadczenia**.

W praktyce wyglÄ…da to tak, jakbyÅ›my dali maszynie duÅ¼Ä… liczbÄ™ przykÅ‚adÃ³w i pozwolili jej samodzielnie odkryÄ‡ wzorce, ktÃ³re rzÄ…dzÄ… danymi. Komputer nie dostaje gotowej instrukcji â€jak dokÅ‚adnie coÅ› zrobiÄ‡â€. Zamiast tego uczy siÄ™, **co dziaÅ‚a najlepiej**, obserwujÄ…c wyniki swoich wÅ‚asnych prÃ³b.

![ML]({{ site.baseurl }}/assets/intro-machine-learning.png){:title="machine learning" class="img-responsive"}


W uczeniu maszynowym kluczowe sÄ… trzy elementy:

**1. Dane**  
To nasz materiaÅ‚ treningowy â€” im lepszy i bardziej rÃ³Å¼norodny, tym trafniejsze wnioski.

**2. Model**  
To matematyczna konstrukcja, ktÃ³ra prÃ³buje dopasowaÄ‡ reguÅ‚y do danych. Na poczÄ…tku jest â€pustaâ€, nie wie nic.

**3. Trenowanie**  
To proces, w ktÃ³rym model robi prognozÄ™, porÃ³wnuje jÄ… z prawdÄ… i poprawia swoje wewnÄ™trzne ustawienia, aby nastÄ™pnym razem przewidzieÄ‡ lepiej.


CaÅ‚y mechanizm polega na nieustannym **uczeniu siÄ™ na bÅ‚Ä™dach**.  
Model po kaÅ¼dej iteracji mierzy, jak bardzo siÄ™ pomyliÅ‚ (to jest tzw. *strata*), a nastÄ™pnie â€” dziÄ™ki metodzie **gradientu** â€” przesuwa swoje parametry tak, aby bÅ‚Ä…d spadaÅ‚. MaÅ‚ymi krokami, ale konsekwentnie.

Dlatego mÃ³wimy, Å¼e uczenie maszynowe to **systematyczne zmniejszanie bÅ‚Ä™du**, aÅ¼ model stanie siÄ™ na tyle precyzyjny, Å¼e moÅ¼emy go wykorzystaÄ‡ do przewidywania nowych, nieznanych danych.

Czy widziesz, jak wszystko zaczyna Å‚Ä…czyÄ‡Â siÄ™Â w caÅ‚oÅ›Ä‡? 

---

## ğŸ‘‰ Cechy i etykieta â€“ dwa filary ML

KaÅ¼dy model ML dziaÅ‚a na bardzo prostym zaÅ‚oÅ¼eniu:

- **cechy (features)** â€“ to dane wejÅ›ciowe,  
- **etykieta (label)** â€“ to wartoÅ›Ä‡, ktÃ³rÄ… model ma przewidzieÄ‡.

PrzykÅ‚ady z naszych danych:

**Spotify â€“ cechy**
- tempo  
- energia  
- tanecznoÅ›Ä‡  

**Spotify â€“ etykieta**
- popularnoÅ›Ä‡  

**Filmy â€“ cechy**
- czas trwania  
- Meta_score  
- liczba gÅ‚osÃ³w  

**Filmy â€“ etykieta**
- ocena IMDb  

Model zawsze szuka **zaleÅ¼noÅ›ci** miÄ™dzy zestawem cech a etykietÄ….

---

## ğŸ‘‰ Co to znaczy, Å¼e model siÄ™ â€uczyâ€?

Podczas treningu skÅ‚ada siÄ™ to z kilku krokÃ³w:

1. model prÃ³buje stworzyÄ‡ jakiÅ› wzÃ³r,  
2. sprawdza, **jak bardzo siÄ™ myli**,  
3. prÃ³buje poprawiÄ‡ ten wzÃ³r,  
4. znowu mierzy bÅ‚Ä…d,  
5. poprawia wzÃ³r jeszcze trochÄ™â€¦

Tak dziaÅ‚a â€uczenie siÄ™ na bÅ‚Ä™dachâ€.  
Model sprawdza kaÅ¼dÄ… prÃ³bÄ™, ocenia jÄ…, a potem minimalnie zmienia strategiÄ™.  
W `scikit-learn` nie widzimy tych krokÃ³w, ale one tam sÄ….  Ten proces powtarza siÄ™ wiele razy i nazywamy go **iteracjami**.

---

## ğŸ‘‰ Co to jest bÅ‚Ä…d modelu?

ZaÅ‚Ã³Å¼my, Å¼e model przewidziaÅ‚ popularnoÅ›Ä‡ utworu:

- przewidywana wartoÅ›Ä‡: `55`  
- prawdziwa wartoÅ›Ä‡: `60` 

`BÅ‚Ä…d = 60 â€“ 55 = 5`

Im mniejszy bÅ‚Ä…d, tym lepszy model.  

Uczenie polega na tym, Å¼e model **stara siÄ™ te bÅ‚Ä™dy minimalizowaÄ‡**.

To, jak bardzo model siÄ™ myli, jest mierzone rÃ³Å¼nymi wskaÅºnikami, np.:

- RÂ² dla regresji  
- `accuracy` dla klasyfikacji  

---

## ğŸ‘‰ Decision boundary â€“ granica decyzji

Gdy model klasyfikuje dane (np. popularny / niepopularny), potrzebuje ustaliÄ‡ miejsce, w ktÃ³rym â€podejmuje decyzjÄ™â€.

Najprostszy przypadek:

- jeÅ›li energia > X â†’ popularny
- jeÅ›li energia <= X â†’ niepopularny


To miejsce X jest **granicÄ… decyzji**.  

Przy dwÃ³ch cechach taka granica staje siÄ™ liniÄ… na wykresie.  

Przy trzech â€“ pÅ‚aszczyznÄ….  

Przy piÄ™tnastu â€“ czymÅ›, czego nie da siÄ™ narysowaÄ‡, ale dziaÅ‚a tak samo.

---

## ğŸ‘‰ Nowe narzÄ™dzia, ktÃ³re pokazujÄ…, jak model myÅ›li

### **1. `model.coef_`**
Pokazuje wpÅ‚yw kaÅ¼dej cechy (dla regresji liniowej).  
DziÄ™ki temu moÅ¼na zobaczyÄ‡, ktÃ³re cechy sÄ… waÅ¼niejsze.

> model.coef_

PrzykÅ‚ad interpretacji:  
jeÅ›li `coef_` dla `No_of_Votes` jest wiÄ™ksze niÅ¼ dla `Duration`,  
to liczba gÅ‚osÃ³w mocniej wpÅ‚ywa na ocenÄ™ niÅ¼ dÅ‚ugoÅ›Ä‡ filmu.

```python
from sklearn.linear_model import LinearRegression

X = df_small[["duration_ms", "energy", "danceability"]]
y = df_small["popularity"]

model = LinearRegression()
model.fit(X, y)

for feature, coef in zip(X.columns, model.coef_):
    print(feature, "â†’", coef)
```

### Co to kod robi?

- `X` â€“ cechy, czyli dane wejÅ›ciowe (tu: 3 kolumny Spotify)
- `y` â€“ etykieta, czyli to, co przewidujemy (popularnoÅ›Ä‡)
- `model.fit(X, y)` â€“ trening modelu
- `model.coef_` â€“ liczby, ktÃ³re pokazujÄ… wpÅ‚yw kaÅ¼dej cechy
- pÄ™tla `for` â€“ wypisuje nazwy cech i ich wspÃ³Å‚czynniki

Co wynika z tego kodu, czy widzisz coÅ› ciekawego w wyniku? 

---

### **2. `model.intercept_`**
Punkt startowy modelu â€“ wartoÅ›Ä‡, od ktÃ³rej zaczyna.

> model.intercept_

---

### **3. `model.predict()`**
Predykcja dla danych.  
MoÅ¼esz podejrzeÄ‡ wynik np. dla 3 pierwszych filmÃ³w:

> model.predict(X.iloc[:3])

---

### **4. `plt.contourf()`**  
Nowy rodzaj wizualizacji â€“ koloruje obszar wykresu tak, jak â€widziâ€ go model.  
To pozwala zobaczyÄ‡ granicÄ™ decyzji dla klasyfikacji dwuwymiarowej.

Å»eby to zrobiÄ‡, potrzebna jest jeszcze jedna funkcja:

### **5. `np.meshgrid()`**
Tworzy siatkÄ™ punktÃ³w w tle wykresu (takie tÅ‚o, ktÃ³re model â€pytaâ€ o decyzjÄ™).

UÅ¼ywa siÄ™ ich razem, Å¼eby zobaczyÄ‡, jak model dzieli przestrzeÅ„ cech na grupy.

---

## ğŸ‘‰ Co daje taka wiedza?

- rozumiesz, jak powstaje wynik modelu  
- wiesz, dlaczego model moÅ¼e siÄ™ myliÄ‡  
- potrafisz lepiej dobraÄ‡ cechy  
- Å‚atwiej zauwaÅ¼yÄ‡, kiedy model prÃ³buje â€nauczyÄ‡ siÄ™ za bardzoâ€ (przeuczenie)

To nie sÄ… szczegÃ³Å‚y matematyczne â€“ to **intuicja**, ktÃ³ra okreÅ›la, kiedy model ma sens, a kiedy nie.

---

## ğŸ‘‰ KrÃ³tkie podsumowanie

Uczenie maszynowe w Å›rodku zawiera wiele informacji, ktÃ³re "my" jako ludzie rozumiemy, ale nie chcemy ogarniaÄ‡ ich rÄ™cznie: 

- cechy â†’ dane wejÅ›ciowe  
- etykieta â†’ odpowiedÅº, ktÃ³rej model musi siÄ™ nauczyÄ‡  
- bÅ‚Ä…d â†’ rÃ³Å¼nica miÄ™dzy tym, co przewidziaÅ‚, a prawdÄ…  
- iteracje â†’ ciÄ…gÅ‚e poprawianie modelu  
- decision boundary â†’ granica klasyfikacji  
- coef_ i intercept_ â†’ wskazÃ³wki, co ma najwiÄ™kszy wpÅ‚yw  
- contourf + meshgrid â†’ wizualizacja decyzji w klasyfikacji 2D

W kolejnych zajÄ™ciach zobaczymy, jak wykorzystaÄ‡ tÄ™ wiedzÄ™, kiedy zaczniemy porÃ³wnywaÄ‡ rÃ³Å¼ne modele i sprawdzaÄ‡, dlaczego jeden dziaÅ‚a lepiej niÅ¼ drugi.
