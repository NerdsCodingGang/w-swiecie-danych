---
title: 12. Jak dziaÅ‚a uczenie maszynowe od Å›rodka?
layout: post
---

W tej lekcji zajrzymy trochÄ™ gÅ‚Ä™biej pod powierzchniÄ™ tego, co robi model ML, kiedy â€uczy siÄ™â€ na danych.  Do tej pory trenowaÅ‚yÅ›my modele tak po prostu â€“ kilka komend i dziaÅ‚a. Teraz zobaczymy, **co naprawdÄ™ dzieje siÄ™ w Å›rodku**.

Nie chcemy traktowaÄ‡ modelu jak czarnej skrzynki, sprÃ³bujemy zrozumieÄ‡, *dlaczego coÅ› dziaÅ‚a*, *dlaczego czasem nie dziaÅ‚a* i *co moÅ¼na poprawiÄ‡?*.

## Uczenie Maszynowe

Machine learning, czyli uczenie maszynowe, to tak naprawdÄ™ **bardzo uporzÄ…dkowany sposÃ³b uczenia komputerÃ³w na podstawie doÅ›wiadczenia**.

W praktyce wyglÄ…da to tak, jakbyÅ›my dali maszynie duÅ¼Ä… liczbÄ™ przykÅ‚adÃ³w i pozwolili jej samodzielnie odkryÄ‡ wzorce, ktÃ³re rzÄ…dzÄ… danymi. Komputer nie dostaje gotowej instrukcji â€jak dokÅ‚adnie coÅ› zrobiÄ‡â€. Zamiast tego uczy siÄ™, **co dziaÅ‚a najlepiej**, obserwujÄ…c wyniki swoich wÅ‚asnych prÃ³b.

![ML]({{ site.baseurl }}/assets/intro-machine-learning.png){:title="machine learning" class="img-responsive"}


W uczeniu maszynowym kluczowe sÄ… trzy elementy:

ğŸŸ£ **1. Dane**  
To nasz materiaÅ‚ treningowy â€” im lepszy i bardziej rÃ³Å¼norodny, tym trafniejsze wnioski.

ğŸŸ£ **2. Model**  
To matematyczna konstrukcja, ktÃ³ra prÃ³buje dopasowaÄ‡ reguÅ‚y do danych. Na poczÄ…tku jest â€pustaâ€, nie wie nic.

ğŸŸ£ **3. Trenowanie**  
To proces, w ktÃ³rym model robi prognozÄ™, porÃ³wnuje jÄ… z prawdÄ… i poprawia swoje wewnÄ™trzne ustawienia, aby nastÄ™pnym razem przewidzieÄ‡ lepiej.


CaÅ‚y mechanizm polega na nieustannym **uczeniu siÄ™ na bÅ‚Ä™dach**.  
Model po kaÅ¼dej iteracji mierzy, jak bardzo siÄ™ pomyliÅ‚ (to jest tzw. *strata*), a nastÄ™pnie â€” dziÄ™ki metodzie **gradientu** â€” przesuwa swoje parametry tak, aby bÅ‚Ä…d spadaÅ‚. MaÅ‚ymi krokami, ale konsekwentnie.

Dlatego mÃ³wimy, Å¼e uczenie maszynowe to **systematyczne zmniejszanie bÅ‚Ä™du**, aÅ¼ model stanie siÄ™ na tyle precyzyjny, Å¼e moÅ¼emy go wykorzystaÄ‡ do przewidywania nowych, nieznanych danych.

### Czy widziesz, jak wszystko co do tej pory robimy zaczna siÄ™Â zaczyna Å‚Ä…czyÄ‡Â siÄ™Â w caÅ‚oÅ›Ä‡? 

WczeÅ›niej naszym zadaniem byÅ‚o poznanie dane, oczyszczenie je, policzenie statystyk, zrobienie wykresÃ³w, szukanie zaleÅ¼noÅ›ci. Wiemy jak stworzyÄ‡ mini-raport. 
W rozdziale 10 byÅ‚o przejÅ›cie przez trenowanie â€krok po krokuâ€. Ten etap miaÅ‚ pokazaÄ‡, **jak wyglÄ…da praca z modelem od strony uÅ¼ytkownika**.

Teraz widaÄ‡, Å¼e wszystkie wczeÅ›niejsze Ä‡wiczenia miaÅ‚y sens:  to wÅ‚aÅ›nie one tworzÄ… **podstawÄ™, na ktÃ³rej model moÅ¼e siÄ™ uczyÄ‡**.

Uczenie maszynowe to w gruncie rzeczy **systematyczne zmniejszanie bÅ‚Ä™du** â€” powoli, iteracyjnie, aÅ¼ model zaczyna przewidywaÄ‡ coraz dokÅ‚adniej.  
KaÅ¼dy krok wykonany wczeÅ›niej byÅ‚ przygotowaniem do tego momentu.

---

## ğŸ‘‰ Cechy i etykieta â€“ dwa filary ML

KaÅ¼dy model ML dziaÅ‚a na bardzo prostym zaÅ‚oÅ¼eniu:

- **cechy (features)** â€“ to dane wejÅ›ciowe,  
- **etykieta (label)** â€“ to wartoÅ›Ä‡, ktÃ³rÄ… model ma przewidzieÄ‡.

PrzykÅ‚ady z naszych danych:

ğŸµ **Spotify â€“ cechy**
- tempo  
- energia  
- tanecznoÅ›Ä‡  

 ğŸµ **Spotify â€“ etykieta**
- popularnoÅ›Ä‡  

 ğŸ¬ **Filmy â€“ cechy**
- czas trwania  
- Meta_score  
- liczba gÅ‚osÃ³w  

ğŸ¬ **Filmy â€“ etykieta**
- ocena IMDb  

Model zawsze szuka **zaleÅ¼noÅ›ci** miÄ™dzy zestawem cech a etykietÄ….

---

## ğŸ‘‰ Co to znaczy, Å¼e model siÄ™ â€uczyâ€?

Podczas treningu skÅ‚ada siÄ™ to z kilku krokÃ³w:

1. model prÃ³buje stworzyÄ‡ jakiÅ› wzÃ³r,  
2. sprawdza, **jak bardzo siÄ™ myli**,  
3. prÃ³buje poprawiÄ‡ ten wzÃ³r,  
4. znowu mierzy bÅ‚Ä…d,  
5. poprawia wzÃ³r jeszcze trochÄ™â€¦

Tak dziaÅ‚a â€uczenie siÄ™ na bÅ‚Ä™dachâ€.  
Model sprawdza kaÅ¼dÄ… prÃ³bÄ™, ocenia jÄ…, a potem minimalnie zmienia strategiÄ™.  
W `scikit-learn` nie widzimy tych krokÃ³w, ale one tam sÄ….  Ten proces powtarza siÄ™ wiele razy i nazywamy go **iteracjami**.

---

## ğŸ‘‰ Co to jest bÅ‚Ä…d modelu?

ZaÅ‚Ã³Å¼my, Å¼e model przewidziaÅ‚ popularnoÅ›Ä‡ utworu:

- przewidywana wartoÅ›Ä‡: `55`  
- prawdziwa wartoÅ›Ä‡: `60` 

`BÅ‚Ä…d = 60 â€“ 55 = 5`

Im mniejszy bÅ‚Ä…d, tym lepszy model.  

Uczenie polega na tym, Å¼e model **stara siÄ™ te bÅ‚Ä™dy minimalizowaÄ‡**.

To, jak bardzo model siÄ™ myli, jest mierzone rÃ³Å¼nymi wskaÅºnikami, np.:

- RÂ² dla regresji  
- `accuracy` dla klasyfikacji  

---

## ğŸ‘‰ Decision boundary â€“ granica decyzji

Gdy model klasyfikuje dane (np. popularny / niepopularny), potrzebuje ustaliÄ‡ miejsce, w ktÃ³rym â€podejmuje decyzjÄ™â€.

Najprostszy przypadek:

- jeÅ›li energia > X â†’ popularny
- jeÅ›li energia <= X â†’ niepopularny


To miejsce X jest **granicÄ… decyzji**.  


### ... trudne do wyobraÅ¼enia?

Wiemy!

Dlaczego tak trudno nam sobie tÄ™ granicÄ™ wyobraziÄ‡? Bo model ustala tÄ™ granicÄ™ **nie na oko**, tylko na podstawie danych.  

Model "zastanawia siÄ™:
_W ktÃ³rym miejscu najlepiej oddzieliÄ‡ jednÄ… grupÄ™ od drugiej?_

Przy jednej cesze granica to *po prostu jedna liczba X*.  
Przy dwÃ³ch â€” linia na wykresie.  
Przy trzech â€” pÅ‚aszczyzna.  
Przy piÄ™tnastu â€” czego juÅ¼ nie da siÄ™ narysowaÄ‡, ale dziaÅ‚a dokÅ‚adnie tak samo.

---

###  PrzykÅ‚ad z 2 cechami

ZaÅ‚Ã³Å¼my, Å¼e bierzemy dwie cechy:  
`energy` i `danceability`.

KaÅ¼dy utwÃ³r to jeden punkt na wykresie.  
JeÅ›li oznaczymy:

- popularne utwory na fioletowo  
- niepopularne na szaro

moÅ¼emy sprÃ³bowaÄ‡ **od rÄ™ki** narysowaÄ‡ liniÄ™, ktÃ³ra oddzieli te dwie grupy.

Model robi to samo â€” tylko precyzyjniej.


---

PoniÅ¼szy kod jest doÅ›Ä‡ prosty.  
Nie rysuje jeszcze tÅ‚a ani mapy decyzji, tylko pokazuje:

1. dane na scatterze  
2. liniÄ™ granicznÄ…, jakÄ… znalazÅ‚ model


![granica]({{ site.baseurl }}/assets/energy-dance.png){:title="granica decyzji" class="img-responsive"}



```python
from sklearn.linear_model import LogisticRegression  
import numpy as np  
import matplotlib.pyplot as plt  
 
print("Bierzemy tylko dwie cechy")
X = df_small[["energy", "danceability"]]  
y = (df_small["popularity"] > 70).astype(int)  
  
model = LogisticRegression()  
model.fit(X, y)  
  
print("Rysowanie punktÃ³w") 
plt.scatter(df_small["energy"], df_small["danceability"], c=y, cmap="coolwarm", alpha=0.5)  
  
print("Tworzymy prostÄ… liniÄ™ granicznÄ…")
x_vals = np.linspace(X["energy"].min(), X["energy"].max(), 100)  
y_vals = -(model.coef_[0][0] * x_vals + model.intercept_[0]) / model.coef_[0][1]  

plt.plot(x_vals, y_vals, color="black")  
plt.xlabel("energy")  
plt.ylabel("danceability")  
plt.title("Granica decyzji dla LogisticRegression")  
plt.show()
```


- `model.fit(X, y)`  -  Model nauczyÅ‚ siÄ™, gdzie znajdujÄ… siÄ™ â€fioletoweâ€ i â€szareâ€ punkty.

- `model.coef_ + model.intercept_` - To wÅ‚aÅ›nie liczby, ktÃ³re definiujÄ… granicÄ™ miÄ™dzy klasami. Nie musisz ich teraz analizowaÄ‡ â€” chodzi o to, Å¼e model ich uÅ¼ywa.

- `plot(x_vals, y_vals)`  - Rysujemy liniÄ™, ktÃ³ra wedÅ‚ug modelu najlepiej oddziela dwie grupy.

Po uruchomieniu kodu zobaczysz wykres:  
punkty + czarna linia, ktÃ³ra jest wÅ‚aÅ›nie **decision boundary**.

Od tego momentu model moÅ¼e podjÄ…Ä‡ decyzjÄ™ dla *nowego utworu*, ktÃ³rego nigdy wczeÅ›niej nie widziaÅ‚:

- jeÅ›li znajdzie siÄ™ â€po tej stronie liniiâ€ â†’ popularny  
- jeÅ›li po drugiej â†’ niepopularny

To jest caÅ‚a istota klasyfikacji.

Zrozumienie granicy decyzji sprawia, Å¼e zaczynamy widzieÄ‡ ML nie jako â€czarnÄ… skrzynkÄ™â€,  
ale jako **system, ktÃ³ry szuka najlepszego sposobu oddzielenia jednych punktÃ³w od drugich**.


---

## ğŸ‘‰ Nowe narzÄ™dzia, ktÃ³re pokazujÄ…, jak model myÅ›li

### **1. `model.coef_`**
Pokazuje wpÅ‚yw kaÅ¼dej cechy (dla regresji liniowej).  
DziÄ™ki temu moÅ¼na zobaczyÄ‡, ktÃ³re cechy sÄ… waÅ¼niejsze.

> model.coef_

PrzykÅ‚ad interpretacji:  
> AnalizujÄ…c wpÅ‚yw cech na ocenÄ™ filmu IMDb:
> jeÅ›li `coef_` dla `No_of_Votes` jest wiÄ™ksze niÅ¼ dla `Duration`,  
> to liczba gÅ‚osÃ³w mocniej wpÅ‚ywa na ocenÄ™ niÅ¼ dÅ‚ugoÅ›Ä‡ filmu.

SpÃ³jrzmy na utwory

```python
from sklearn.linear_model import LinearRegression

X = df_small[["duration_ms", "energy", "danceability"]]
y = df_small["popularity"]

model = LinearRegression()
model.fit(X, y)

for feature, coef in zip(X.columns, model.coef_):
    print(feature, "â†’", coef)
```


- `X` â€“ cechy, czyli dane wejÅ›ciowe (tu: 3 kolumny Spotify)
- `y` â€“ etykieta, czyli to, co przewidujemy (popularnoÅ›Ä‡)
- `model.fit(X, y)` â€“ trening modelu
- `model.coef_` â€“ liczby, ktÃ³re pokazujÄ… wpÅ‚yw kaÅ¼dej cechy
- pÄ™tla `for` â€“ wypisuje nazwy cech i ich wspÃ³Å‚czynniki

---

### **2. `model.intercept_`**

`model.intercept_` to **wartoÅ›Ä‡ poczÄ…tkowa modelu**, czyli liczba, od ktÃ³rej model â€zaczyna przewidywanieâ€, zanim weÅºmie pod uwagÄ™ jakiekolwiek cechy.

MoÅ¼na to traktowaÄ‡ jako:
**â€przewidywana wartoÅ›Ä‡ wtedy, gdy wszystkie cechy majÄ… wartoÅ›Ä‡ zeroâ€.**

To brzmi abstrakcyjnie, wiÄ™c zobaczmy to na przykÅ‚adzie z danymi Spotify.

---

####  Co oznacza intercept w praktyce?

ZaÅ‚Ã³Å¼my, Å¼e trenujemy model, ktÃ³ry przewiduje popularnoÅ›Ä‡ na podstawie:

- tempo  
- energia  
- tanecznoÅ›Ä‡  

Model musi mieÄ‡ jakiÅ› **punkt startowy**.  
Nawet jeÅ›li wszystkie cechy = 0 (co w muzyce nie jest realistyczne, ale matematycznie konieczne), model powinien mÃ³c zwrÃ³ciÄ‡ jakÄ…Å› wartoÅ›Ä‡.

TÄ… wartoÅ›ciÄ… jest **intercept**.

To takie â€przesuniÄ™cieâ€ caÅ‚ej funkcji w gÃ³rÄ™ lub w dÃ³Å‚, Å¼eby dopasowaÄ‡ jÄ… do rzeczywistych danych.


---

### **3. `model.predict()`**

Predykcja to moment, w ktÃ³rym model **zastosowuje to, czego siÄ™ nauczyÅ‚**, do konkretnych danych.  
Do tej pory model tylko trenowaÅ‚: porÃ³wnywaÅ‚ swoje wyniki z prawdÄ… i poprawiaÅ‚ parametry.  
Teraz po prostu dostaje wiersz danych i odpowiada:

**â€Na podstawie tych cech przewidujÄ™, Å¼e wynik bÄ™dzie taki.â€**

MoÅ¼esz podejrzeÄ‡ wynik np. dla 3 pierwszych filmÃ³w:

> model.predict(X.iloc[:3])

---

### **4. `plt.contourf()`**  
Nowy rodzaj wizualizacji â€“ koloruje obszar wykresu tak, jak â€widziâ€ go model.  
To pozwala zobaczyÄ‡ granicÄ™ decyzji dla klasyfikacji dwuwymiarowej.

Å»eby to zrobiÄ‡, potrzebna jest jeszcze jedna funkcja:

### **5. `np.meshgrid()`**
Tworzy siatkÄ™ punktÃ³w w tle wykresu (takie tÅ‚o, ktÃ³re model â€pytaâ€ o decyzjÄ™).

UÅ¼ywa siÄ™ ich razem, Å¼eby zobaczyÄ‡, jak model dzieli przestrzeÅ„ cech na grupy.

```python
import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression, LogisticRegression

# --- 1. Dane: wybieramy cechy i etykietÄ™ ---------------------------
X = df_small[["tempo", "energy", "danceability"]]
y = df_small["popularnoÅ›Ä‡"]

# Binarna wersja popularnoÅ›ci (do decision boundary)
y_class = (df_small["popularnoÅ›Ä‡"] > 70).astype(int)

# --- 2. Model regresyjny (przewiduje liczbÄ™) -----------------------
reg = LinearRegression()
reg.fit(X, y)

print("WSPÃ“ÅCZYNNIKI (coef_):")
for feature, coef in zip(X.columns, reg.coef_):
    print(f"{feature} â†’ {coef:.4f}")

print("\nINTERCEPT:")
print(reg.intercept_)

print("\nPREDYKCJE DLA 3 PIERWSZYCH UTWORÃ“W:")
print(reg.predict(X.iloc[:3]))

# --- 3. Model klasyfikacji (potrzebny do decision boundary) --------
clf = LogisticRegression()
clf.fit(X[["energy", "danceability"]], y_class)

# --- 4. Wizualizacja granicy decyzji ------------------------------

# Tworzymy siatkÄ™ punktÃ³w (energia i tanecznoÅ›Ä‡)
x_min, x_max = X["energy"].min(), X["energy"].max()
y_min, y_max = X["danceability"].min(), X["danceability"].max()
xx, yy = np.meshgrid(
    np.linspace(x_min, x_max, 200),
    np.linspace(y_min, y_max, 200)
)

# Przewidywanie dla kaÅ¼dego punktu siatki
Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])
Z = Z.reshape(xx.shape)

# Rysujemy obszary decyzji
plt.contourf(xx, yy, Z, alpha=0.3, cmap="coolwarm")

# Dodajemy prawdziwe punkty
plt.scatter(X["energy"], X["danceability"], c=y_class, cmap="coolwarm", edgecolor="k")

plt.xlabel("energy")
plt.ylabel("danceability")
plt.title("Granica decyzji modelu (popularne vs niepopularne)")
plt.show()
```

---

## ğŸ‰  WOW!

Uczenie maszynowe pod spodem zawiera wiele informacji, ktÃ³re "my" jako ludzie rozumiemy, ale nie chcemy ogarniaÄ‡ ich rÄ™cznie: 

MaÅ‚y sÅ‚owniczek pojÄ™Ä‡:
- cechy â†’ dane wejÅ›ciowe  
- etykieta â†’ odpowiedÅº, ktÃ³rej model musi siÄ™ nauczyÄ‡  
- bÅ‚Ä…d â†’ rÃ³Å¼nica miÄ™dzy tym, co przewidziaÅ‚, a prawdÄ…  
- iteracje â†’ ciÄ…gÅ‚e poprawianie modelu  
- decision boundary â†’ granica klasyfikacji  
- coef_ i intercept_ â†’ wskazÃ³wki, co ma najwiÄ™kszy wpÅ‚yw  
- contourf + meshgrid â†’ wizualizacja decyzji w klasyfikacji 2D

Jak wykorzystaÄ‡ tÄ™ wiedzÄ™, kiedy zaczniemy porÃ³wnywaÄ‡ rÃ³Å¼ne modele i sprawdzaÄ‡, dlaczego jeden dziaÅ‚a lepiej niÅ¼ drugi.
