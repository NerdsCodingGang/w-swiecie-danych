---
title: 15. WybÃ³r cech (feature selection)
layout: post
---

Wy jeszcze tutaj zaglÄ…dacieâ€¦? ğŸ‘€  

no to naprawdÄ™ nie macie doÅ›Ä‡ naszych warsztatÃ³w.  
Serce roÅ›nie! ğŸ’œ

W tym rozdziale zrobimy coÅ› bardzo extra!
 ~  sprawdzimy **ktÃ³re cechy naprawdÄ™ majÄ… znaczenie**, a ktÃ³re tylko udajÄ…, Å¼e coÅ› wnoszÄ….



To waÅ¼ny krok, bo model **nie potrzebuje wszystkiego**.  
Czasem dwie cechy sÄ… prawie identyczne.  
Czasem jedna jest kompletnie bezuÅ¼yteczna.  
Czasem dodanie wiÄ™kszej liczby cech *psuje* wynik.

Czas trochÄ™Â zamieszaÄ‡ w naszych danych i sprawdziÄ‡, co tak pomaga modelowi przewidywaÄ‡ popularnoÅ›Ä‡ utworÃ³w na Spotify

![salem]({{ site.baseurl }}/assets/salem-mix.gif){:title="mieszamy" class="img-responsive"}


---

## Dlaczego wybÃ³r cech jest interesujÄ…cy?

Modele uczÄ… siÄ™ z danych.  
JeÅ›li majÄ… za duÅ¼o szumu, mogÄ…:

- myliÄ‡ siÄ™ czÄ™Å›ciej,  
- dziaÅ‚aÄ‡ wolniej,  
- â€uczyÄ‡ siÄ™ na pamiÄ™Ä‡â€ (overfitting),  
- dawaÄ‡ mniej stabilne wyniki.

Dlatego dobry Data Scientist zawsze zadaje pytanie:

> "KtÃ³re kolumny faktycznie pomagajÄ… przewidywaÄ‡ to, co mnie interesuje?â€

---

## Krok 1: sprawdÅºmy korelacje miÄ™dzy cechami

Zacznijmy od podstaw: korelacja pokazuje, ktÃ³re kolumny **rosnÄ… lub malejÄ… razem**.

`df_small[["tempo", "energy", "danceability", "valence", "loudness", "popularity"]].corr()`

To szybki sposÃ³b, Å¼eby zobaczyÄ‡:

- ktÃ³re cechy sÄ… ze sobÄ… podobne,  
- ktÃ³re mogÄ… przewidywaÄ‡ popularnoÅ›Ä‡,  
- ktÃ³re moÅ¼na pominÄ…Ä‡.

PodpowiedÅº do analizy:
- wartoÅ›ci bliskie **1** â†’ cechy bardzo powiÄ…zane  
- wartoÅ›ci bliskie **0** â†’ zwiÄ…zek sÅ‚aby  
- wartoÅ›ci **ujemne** â†’ im wiÄ™cej jednej cechy, tym mniej drugiej  

---

## Krok 2: sprawdzamy znaczenie cech (feature_importances_)

Modele drzewiaste, takie jak `DecisionTreeRegressor` czy `RandomForestRegressor`, majÄ… bardzo wygodnÄ… wÅ‚aÅ›ciwoÅ›Ä‡:

`model.feature_importances_`

To liczby mÃ³wiÄ…ce, **jak mocno kaÅ¼da cecha wpÅ‚ywa na przewidywanie**.

ZrÃ³bmy maÅ‚y przykÅ‚ad na Spotify:
```python
from sklearn.ensemble import RandomForestRegressor

X = df_small[["tempo", "energy", "danceability", "valence", "loudness", "duration_ms"]]  
y = df_small["popularity"]  
  
model = RandomForestRegressor()  
model.fit(X, y)  

for feature, score in zip(X.columns, model.feature_importances_):  
    print(feature, "â†’", score)
```

**Jak to zinterpretowaÄ‡?**

- im wyÅ¼szy wynik, tym **waÅ¼niejsza cecha**,  
- wyniki sumujÄ… siÄ™ do 1,  
- moÅ¼esz porÃ³wnaÄ‡, ktÃ³re cechy naprawdÄ™ â€ciÄ…gnÄ…â€ model.

---

## Krok 3: porÃ³wnujemy model z 3 cechami vs z 6

To bardzo praktyczne Ä‡wiczenie, by rozumieÄ‡ jak dodawanie cech wpÅ‚ywa na model.

Najpierw model z trzema cechami:

> X3 = df_small[["tempo", "energy", "danceability"]]

Potem model z szeÅ›cioma cechami:

> X6 = df_small[["tempo", "energy", "danceability", "valence", "loudness", "duration_ms"]]

NastÄ™pnie mierzysz ich jakoÅ›Ä‡:

- MAE  
- MSE  
- RÂ²  

i porÃ³wnujesz wyniki!

```python
# tu juÅ¼ czas na TwÃ³j kod! 
```

To pokaÅ¼e Ci bardzo szybko:

- czy dodatkowe cechy faktycznie pomagajÄ…,  
- czy tylko dodajÄ… szumu,  
- czy model staje siÄ™ stabilniejszy.

---

## ğŸ‘‰ Mini zadanie (dla Ciebie!)

SprÃ³buj teraz:

1. policzyÄ‡ korelacje wybranych szeÅ›ciu cech z `popularity`,  
2. uruchomiÄ‡ RandomForest na 3 cechach i na 6,  
3. porÃ³wnaÄ‡ wyniki,  
4. napisaÄ‡ jedno krÃ³tkie zdanie:  
   **â€NajwiÄ™kszy wpÅ‚yw maâ€¦â€** albo **â€Dodanie cech X i Y poprawiÅ‚o/pogorszyÅ‚o wynik modelu.â€**

To jest dokÅ‚adnie ten sposÃ³b myÅ›lenia, ktÃ³ry buduje dobre projekty!


_JeÅ›li masz Githuba pobierz plik ipynb z tego rozdziaÅ‚u moÅ¼esz go wgraÄ‡Â jako element Twojego przyszÅ‚ego portfolio i pokazaÄ‡, Å¼e rozumiesz wybÃ³r cech w ML!_

